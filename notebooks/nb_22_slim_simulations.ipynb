{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Slim simulations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re, os, sys, pickle, pickle, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from pandas import DataFrame, Series\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# my own libaries\n",
    "from GenomicWindows import window\n",
    "import GenomicIntervals\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import variables global to the entire analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import analysis_globals as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local code in the scripts dir on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if str(ag.scripts_dir) not in sys.path:\n",
    "    sys.path.append(str(ag.scripts_dir))\n",
    "\n",
    "import simons_meta_data\n",
    "import hg19_chrom_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Make inline plots vector graphics instead of raster graphics\n",
    "from IPython.display import set_matplotlib_formats\n",
    "# set_matplotlib_formats('pdf', 'svg')\n",
    "set_matplotlib_formats('retina', 'png')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "#matplotlib.rcParams['figure.figsize'] = (20.0, 10.0)\n",
    "\n",
    "import mpld3\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set() # seaborn niceness\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "# lowess for plotting\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore warnings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# silence deprecation warnings (lots from seaborn)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load meta data\n",
    "\n",
    "Easy loading of meta data in a consistent manner across code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "individuals, populations, regions = simons_meta_data.get_meta_data(meta_data_dir=ag.meta_data_dir)\n",
    "\n",
    "chromosome_lengths = dict((k.replace('chr', ''), v) for k, v in hg19_chrom_sizes.hg19_chrom_sizes.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load swept regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32500000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_peak_regions_10 = pd.read_hdf(ag.results_dir / 'extended_peak_regions_10%.hdf')\n",
    "extended_peak_regions_10['chrom'] = 'chrX'\n",
    "(extended_peak_regions_10.end_pos - extended_peak_regions_10.start_pos).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMRCA computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035592882340661172"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "def lamb(i):\n",
    "    # lamb(i) rate of coalescence from i-1 to i\n",
    "    i += 1\n",
    "    return i*(i-1)/2\n",
    "\n",
    "samples = 5 # total samples\n",
    "setsize = 3 # size of clade (we want to see at least one such clade coalesce before time t)\n",
    "t = 1\n",
    "\n",
    "for n in range(setsize, samples+1):\n",
    "    # loop from setsize to samples (3 to 5):\n",
    "    p = 0\n",
    "    for i in range(1, n):\n",
    "        # loop from 1 to n-1:\n",
    "        p += np.prod([lamb(j)/(lamb(j)-lamb(i)) for j in range(1, n) if i != j]) \\\n",
    "        * exp(-lamb(n)*t) \\\n",
    "        * (lamb(i)/(lamb(i)-lamb(n))) \\\n",
    "        * (-exp(-(lamb(i)-lamb(n))*t) + 1)\n",
    "    # combinatorial expression:\n",
    "    p *= scipy.misc.comb(n, setsize) / scipy.misc.comb(samples, setsize)\n",
    "p\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5316066224579469e+35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lamb(x):\n",
    "    x += 1\n",
    "    return x*(x-1)/2\n",
    "\n",
    "\n",
    "N = 3000\n",
    "n = 42\n",
    "t = 1\n",
    "\n",
    "prob = 0\n",
    "for i in range(1, n):\n",
    "    prob += (1 - math.exp(-lamb(i)*t)) * np.prod([lamb(j)/(lamb(j)-lamb(i)) for j in range(1, n) if i != j])\n",
    "prob * scipy.misc.comb(140, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0163968567466686e+36"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.misc.comb(140, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6321205588285577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- math.exp(-lamb(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[-0.0, 1.5, 1.2, 1.1111111111111112, 1.0714285714285714, 1.05, 1.037037037037037, 1.0285714285714285, 1.0227272727272727, 1.0185185185185186, 1.0153846153846153, 1.0129870129870129, 1.011111111111111, 1.0096153846153846, 1.0084033613445378, 1.0074074074074073, 1.006578947368421, 1.0058823529411764, 1.0052910052910053]\n",
      "[-0.0, -0.5, 2.0, 1.4285714285714286, 1.25, 1.1666666666666667, 1.12, 1.0909090909090908, 1.0714285714285714, 1.0576923076923077, 1.0476190476190477, 1.04, 1.0340909090909092, 1.0294117647058822, 1.0256410256410255, 1.0225563909774436, 1.02, 1.0178571428571428, 1.0160427807486632]\n",
      "[-0.0, -0.2, -1.0, 2.5, 1.6666666666666667, 1.4, 1.2727272727272727, 1.2, 1.1538461538461537, 1.1224489795918366, 1.1, 1.0833333333333333, 1.0705882352941176, 1.0606060606060606, 1.0526315789473684, 1.0461538461538462, 1.0408163265306123, 1.0363636363636364, 1.0326086956521738]\n",
      "[-0.0, -0.1111111111111111, -0.42857142857142855, -1.5, 3.0, 1.9090909090909092, 1.5555555555555556, 1.3846153846153846, 1.2857142857142858, 1.2222222222222223, 1.1785714285714286, 1.1470588235294117, 1.123456790123457, 1.105263157894737, 1.0909090909090908, 1.0793650793650793, 1.06993006993007, 1.062111801242236, 1.0555555555555556]\n",
      "[-0.0, -0.07142857142857142, -0.25, -0.6666666666666666, -2.0, 3.5, 2.1538461538461537, 1.7142857142857142, 1.5, 1.375, 1.2941176470588236, 1.2380952380952381, 1.1973684210526316, 1.1666666666666667, 1.1428571428571428, 1.1239669421487604, 1.108695652173913, 1.0961538461538463, 1.0857142857142856]\n",
      "[-0.0, -0.05, -0.16666666666666666, -0.4, -0.9090909090909091, -2.5, 4.0, 2.4, 1.875, 1.6176470588235294, 1.4666666666666666, 1.368421052631579, 1.3, 1.25, 1.2121212121212122, 1.182608695652174, 1.1590909090909092, 1.14, 1.1242603550295858]\n",
      "[-0.0, -0.037037037037037035, -0.12, -0.2727272727272727, -0.5555555555555556, -1.1538461538461537, -3.0, 4.5, 2.6470588235294117, 2.037037037037037, 1.736842105263158, 1.56, 1.4444444444444444, 1.3636363636363635, 1.3043478260869565, 1.2592592592592593, 1.224, 1.1958041958041958, 1.1728395061728396]\n",
      "[-0.0, -0.02857142857142857, -0.09090909090909091, -0.2, -0.38461538461538464, -0.7142857142857143, -1.4, -3.5, 5.0, 2.8947368421052633, 2.2, 1.8571428571428572, 1.6545454545454545, 1.5217391304347827, 1.4285714285714286, 1.36, 1.3076923076923077, 1.2666666666666666, 1.2337662337662338]\n",
      "[-0.0, -0.022727272727272728, -0.07142857142857142, -0.15384615384615385, -0.2857142857142857, -0.5, -0.875, -1.6470588235294117, -4.0, 5.5, 3.142857142857143, 2.3636363636363638, 1.9782608695652173, 1.75, 1.6, 1.4945054945054945, 1.4166666666666667, 1.3571428571428572, 1.3103448275862069]\n",
      "[-0.0, -0.018518518518518517, -0.057692307692307696, -0.12244897959183673, -0.2222222222222222, -0.375, -0.6176470588235294, -1.037037037037037, -1.894736842105263, -4.5, 6.0, 3.391304347826087, 2.5277777777777777, 2.1, 1.8461538461538463, 1.6790123456790123, 1.5612244897959184, 1.4741379310344827, 1.4074074074074074]\n",
      "[-0.0, -0.015384615384615385, -0.047619047619047616, -0.1, -0.17857142857142858, -0.29411764705882354, -0.4666666666666667, -0.7368421052631579, -1.2, -2.142857142857143, -5.0, 6.5, 3.64, 2.6923076923076925, 2.2222222222222223, 1.9428571428571428, 1.7586206896551724, 1.6285714285714286, 1.532258064516129]\n",
      "[-0.0, -0.012987012987012988, -0.04, -0.08333333333333333, -0.14705882352941177, -0.23809523809523808, -0.3684210526315789, -0.56, -0.8571428571428571, -1.3636363636363635, -2.391304347826087, -5.5, 7.0, 3.888888888888889, 2.857142857142857, 2.3448275862068964, 2.04, 1.8387096774193548, 1.6964285714285714]\n",
      "[-0.0, -0.011111111111111112, -0.03409090909090909, -0.07058823529411765, -0.12345679012345678, -0.19736842105263158, -0.3, -0.4444444444444444, -0.6545454545454545, -0.9782608695652174, -1.5277777777777777, -2.64, -6.0, 7.5, 4.137931034482759, 3.022222222222222, 2.467741935483871, 2.1375, 1.9191919191919191]\n",
      "[-0.0, -0.009615384615384616, -0.029411764705882353, -0.06060606060606061, -0.10526315789473684, -0.16666666666666666, -0.25, -0.36363636363636365, -0.5217391304347826, -0.75, -1.1, -1.6923076923076923, -2.888888888888889, -6.5, 8.0, 4.387096774193548, 3.1875, 2.590909090909091, 2.235294117647059]\n",
      "[-0.0, -0.008403361344537815, -0.02564102564102564, -0.05263157894736842, -0.09090909090909091, -0.14285714285714285, -0.21212121212121213, -0.30434782608695654, -0.42857142857142855, -0.6, -0.8461538461538461, -1.2222222222222223, -1.8571428571428572, -3.1379310344827585, -7.0, 8.5, 4.636363636363637, 3.3529411764705883, 2.7142857142857144]\n",
      "[-0.0, -0.007407407407407408, -0.022556390977443608, -0.046153846153846156, -0.07936507936507936, -0.12396694214876033, -0.1826086956521739, -0.25925925925925924, -0.36, -0.4945054945054945, -0.6790123456790124, -0.9428571428571428, -1.3448275862068966, -2.022222222222222, -3.3870967741935485, -7.5, 9.0, 4.885714285714286, 3.5185185185185186]\n",
      "[-0.0, -0.006578947368421052, -0.02, -0.04081632653061224, -0.06993006993006994, -0.10869565217391304, -0.1590909090909091, -0.224, -0.3076923076923077, -0.4166666666666667, -0.5612244897959183, -0.7586206896551724, -1.04, -1.467741935483871, -2.1875, -3.6363636363636362, -8.0, 9.5, 5.135135135135135]\n",
      "[-0.0, -0.0058823529411764705, -0.017857142857142856, -0.03636363636363636, -0.062111801242236024, -0.09615384615384616, -0.14, -0.1958041958041958, -0.26666666666666666, -0.35714285714285715, -0.47413793103448276, -0.6285714285714286, -0.8387096774193549, -1.1375, -1.5909090909090908, -2.3529411764705883, -3.8857142857142857, -8.5, 10.0]\n",
      "[-0.0, -0.005291005291005291, -0.016042780748663103, -0.03260869565217391, -0.05555555555555555, -0.08571428571428572, -0.1242603550295858, -0.1728395061728395, -0.23376623376623376, -0.3103448275862069, -0.4074074074074074, -0.532258064516129, -0.6964285714285714, -0.9191919191919192, -1.2352941176470589, -1.7142857142857142, -2.5185185185185186, -4.135135135135135, -9.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lamb(x):\n",
    "    return x*(x-1)/2\n",
    "\n",
    "t = 10\n",
    "n = 20\n",
    "\n",
    "prob = 0\n",
    "for i in range(1, n+1):\n",
    "    print([lamb(j)/(lamb(j)-lamb(i)) for j in range(1, n+1) if i != j])\n",
    "    prob += lamb(i) * math.exp(-lamb(i)*t) * np.prod([lamb(j)/(lamb(j)-lamb(i)) for j in range(1, n+1) if i != j])\n",
    "prob #* scipy.misc.comb(n, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lamb(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1403635580926885"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "\n",
    "def coal_n_to_l(n, l, t):\n",
    "    \"\"\"Prob of reducing n lineages to l in time t\"\"\"\n",
    "    Q = np.zeros(shape=(n-l+1, n-l+1))\n",
    "    for x in range(n-l):\n",
    "        rate = scipy.misc.comb(n-x, 2) / (2 * pop_size)\n",
    "        Q[x][x] = -rate\n",
    "        Q[x][x+1] = rate\n",
    "    return scipy.linalg.expm(Q*t)[0][-1]\n",
    "\n",
    "def clade_prob(n, l, t, i):\n",
    "    \"\"\"Prob of one among l lineages being ancestor to i among n\"\"\"\n",
    "#     if i == 1 or l == 1:\n",
    "#         return 1\n",
    "#     else:\n",
    "    return scipy.misc.comb(n-i-1, l-2) / scipy.misc.comb(n-1, l-1)\n",
    "        \n",
    "n = 5\n",
    "t = 36\n",
    "pop_size = 300\n",
    "i = 2\n",
    "\n",
    "total_prop = 0\n",
    "for l in range(1, n):\n",
    "    total_prop += coal_n_to_l(n, l, t) * clade_prob(n, l, t, i)\n",
    "total_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-15-ec3f8967074d>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-ec3f8967074d>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    rate = scipy.misc.comb(n-x, 2) / (2 * pop_size)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "        \n",
    "        \n",
    "n = 5\n",
    "t = 360\n",
    "pop_size = 30\n",
    "\n",
    "i = 2\n",
    "\n",
    "#l = 3\n",
    "\n",
    "total_prop = 0\n",
    "\n",
    "for l in [3]:#range(1, n):\n",
    "    \n",
    "    # probability of having l out of n left at time t\n",
    "    Q = np.zeros(shape=(n-l+1, n-l+1))\n",
    "    for x in range(n-l):\n",
    "        rate = scipy.misc.comb(n-x, 2) / (2 * pop_size)\n",
    "        Q[x][x] = -rate\n",
    "        Q[x][x+1] = rate\n",
    "    prop_coalescences_n_to_l = scipy.linalg.expm(Q*t)[0][-1]\n",
    "    prop_coalescences_n_to_l\n",
    "\n",
    "    \n",
    "    if i == 1 or l == 1:\n",
    "        prop_ancestor_to_i = 1 # CHECK THAT THIS IS OK\n",
    "    else:\n",
    "        prop_ancestor_to_i = scipy.misc.comb(n-i-1, l-2) / scipy.misc.comb(n-1, l-1)\n",
    "\n",
    "    assert prop_ancestor_to_i <= 1, prop_ancestor_to_i\n",
    "\n",
    "    prob = prop_coalescences_n_to_l * prop_ancestor_to_i\n",
    "\n",
    "    print(prop_coalescences_n_to_l, prop_ancestor_to_i)\n",
    "\n",
    "    total_prop += prob\n",
    "total_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "- We take demography from Yun Song.\n",
    "- We make sure it is expected to the reduction non-African X/A from an african one of 0.66 reported in Mallick et al., and that it the theoretically predicted pi mathches the one observed in non-Africans. That works if we multiply each Ne in the \"slim_demography\" by 1.1.\n",
    "- **The question is how much to reduce local Ne by**\n",
    "- We simulate with Ne_autosome * 66/75\n",
    "- In simulations we also use a reduced rec rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute empirical X/A values for Africans and non-Africans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute X/A ratio for the males in our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pi on X for Africans and non-Africans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_afr = (pd.read_hdf(ag.steps_dir / 'male_dist_admix_masked_stores/male_dist_data_chrX_100kb.store')\n",
    "            .loc[lambda df: (df.region_1 == 'Africa') & (df.region_2 == 'Africa')]\n",
    "           )\n",
    "dist_nonafr = (pd.read_hdf(ag.steps_dir / 'male_dist_admix_masked_stores/male_dist_data_chrX_100kb.store')\n",
    "            .loc[lambda df: (df.region_1 != 'Africa') & (df.region_2 != 'Africa')]\n",
    "           )\n",
    "dist_nonafr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_mean_dist = dist_afr.dist.mean()\n",
    "nonafr_mean_dist = dist_nonafr.dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_mean_dist, nonafr_mean_dist, nonafr_mean_dist / afr_mean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract likely pi relative to global pi in Africans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list()\n",
    "for tup in extended_peak_regions_10.itertuples():\n",
    "    lst.append(dist_afr.loc[(dist_afr.start >= tup.start_pos) & (dist_afr.end <= tup.end_pos)])\n",
    "afr_dist_regions = pd.concat(lst)\n",
    "\n",
    "lst = list()\n",
    "for tup in extended_peak_regions_10.itertuples():\n",
    "    lst.append(dist_nonafr.loc[(dist_nonafr.start >= tup.start_pos) & (dist_nonafr.end <= tup.end_pos)])\n",
    "nonafr_dist_regions = pd.concat(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_mean_dist_in_regions = afr_dist_regions.dist.mean()\n",
    "nonafr_mean_dist_in_regions = nonafr_dist_regions.dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afr_mean_dist_in_regions, afr_mean_dist, afr_mean_dist_in_regions / afr_mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonafr_mean_dist_in_regions, nonafr_mean_dist, nonafr_mean_dist_in_regions / nonafr_mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonafr_mean_dist_in_regions / afr_mean_dist_in_regions, nonafr_mean_dist / afr_mean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute demographies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_generations = 200000 - 1\n",
    "x_auto_fraction = 0.55\n",
    "\n",
    "def years2gen(y):\n",
    "    return int(1 + sim_generations - y / ag.gen_time)\n",
    "\n",
    "years2gen(sim_generations * ag.gen_time), years2gen(0), sim_generations * ag.gen_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_year = [sim_generations * ag.gen_time, 250000, 150000, 100000, 70000, 50000, 35000, 25000, 15000, 6000]\n",
    "changes_Ne = [20000, 12000, 6000, 4000, 3000, 4000, 6000, 12000, 20000, 100000]\n",
    "sweep_years = [30000, 50000, 70000, 100000]\n",
    "\n",
    "#changes_Ne = [(x*1.15) for x in changes_Ne]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('ticks') :\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13,5), sharey=True)\n",
    "\n",
    "    y = Series(list(reversed(changes_year)))\n",
    "    n = Series(list(reversed(changes_Ne)))\n",
    "    x = [j for i in zip(y.shift(), y) for j in i]\n",
    "    y = [j for i in zip(n, n) for j in i]\n",
    "    x[0] = 1000\n",
    "\n",
    "    auto_demography = list(zip(reversed(x[1::2]), reversed(y[1::2])))\n",
    "\n",
    "    color=next(ax1._get_lines.prop_cycler)['color']\n",
    "    ax1.loglog(x, y, color=color)\n",
    "    ax1.loglog(*list(zip(*auto_demography)), marker='o', color=color, linestyle='None', label='Autosomes');\n",
    "\n",
    "\n",
    "    y = Series(list(reversed(changes_year)))\n",
    "    n = Series(list(reversed(changes_Ne))) * x_auto_fraction\n",
    "    x = [j for i in zip(y.shift(), y) for j in i]\n",
    "    y = [j for i in zip(n, n) for j in i]\n",
    "    x[0] = 1000\n",
    "\n",
    "#     x_demography = [(y, n*x_auto_fraction) for (y, n) in auto_demography]\n",
    "\n",
    "#     color=next(ax1._get_lines.prop_cycler)['color']\n",
    "#     ax1.loglog(x, y, color=color)\n",
    "#     ax1.loglog(*list(zip(*x_demography)), marker='o', color=color, linestyle='None', label='X');\n",
    "#     ax1.set_ylim(1000, 120000)\n",
    "#     ax1.set_xlim(1e3, 1e7) ;\n",
    "#     ax1.set_xlabel('Years')\n",
    "#     ax1.set_ylabel('Population size')\n",
    "#     ax1.legend()\n",
    "\n",
    "    [ax1.axvline(x, linestyle='dotted', color='black') for x in sweep_years]\n",
    "    \n",
    "    \n",
    "    \n",
    "    slim_demography = [(years2gen(y), int(n)) for (y, n) in auto_demography]  ## using auto\n",
    "    g, n = list(zip(*slim_demography))\n",
    "    ax2.loglog([sim_generations-x for x in g], n, marker='o', linestyle='None', \n",
    "               label='Slim pop. size change points\\n(past to present)');\n",
    "    ax2.set_ylim(1000, 120000)\n",
    "    ax2.set_xlim(1e2, 2.2e5) ;\n",
    "    ax2.set_xlabel('Generations')\n",
    "    ax2.set_ylabel('Population size')\n",
    "    ax2.legend()\n",
    "\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use **autosomal** sizes for Slim because it models the X chrom explicitly. To make the X/A ratio lower than 0.75 we scale the population sizes by (e.g. 0.66/0.75) when running the slim simulation.\n",
    "\n",
    "Generation-Ne pairs for changeing population size in Slim simulation (for adding to `workflow.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slim_demography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generations for sweeps in Slim simulations (for adding to `workflow.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_generations = [years2gen(x) for x in sweep_years]\n",
    "sweep_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_generations = 100000\n",
    "\n",
    "# def years2gen(y):\n",
    "#     return int(sim_generations - y / 29)\n",
    "    \n",
    "    \n",
    "# def demography(pop_size, bottle_pop_size, bottle_start, bottle_end):\n",
    "    \n",
    "#     def bottleneck_N(t):\n",
    "#         return int(round(t / (1/bottle_pop_size - (1-t)/pop_size)))\n",
    "\n",
    "#     t = Series([1, 2/3, 1/3])\n",
    "#     demog = DataFrame(dict(bottle_pop_size=t.map(bottleneck_N), \n",
    "#                                    bottle_time=t*(bottle_start - bottle_end)))\n",
    "#     demog['bottle_start'] = round(bottle_start - (bottle_start - bottle_end - demog.bottle_time) / 2).astype(int)\n",
    "#     demog['bottle_end'] = round(bottle_end + (bottle_start - bottle_end - demog.bottle_time) / 2).astype(int)\n",
    "#     demog['pop_size'] = pop_size\n",
    "#     return demog\n",
    "\n",
    "# smallest_x_auto_fraction = 0.5\n",
    "# pop_size = int(20000 * smallest_x_auto_fraction)\n",
    "# bottle_pop_size = int(2000 * smallest_x_auto_fraction)\n",
    "# bottle_start = 100000\n",
    "# bottle_end = 30000\n",
    "\n",
    "# demog = pd.concat([demography(10000, 1000, 100000, 30000),\n",
    "#                   # demography(20000, 2000, 100000, 30000)\n",
    "#                   ])\n",
    "# demog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print for loading into `workflow.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(zip(\n",
    "#     list(demog.pop_size),\n",
    "#     list(years2gen(x) for x in demog.bottle_start),\n",
    "#     list(years2gen(x) for x in demog.bottle_end),\n",
    "#     demog.bottle_pop_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pool-Nielsen computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epoques = list()\n",
    "g, n = list(zip(*slim_demography))\n",
    "gens, Ns = [sim_generations-x for x in g][::-1], n[::-1]\n",
    "for i in range(len(gens)):\n",
    "    if i == 0:\n",
    "        epoques.append((gens[i], Ns[i]))\n",
    "    elif i == len(gens) - 1:\n",
    "        epoques.append((None, Ns[i]))    \n",
    "    else:\n",
    "        epoques.append((gens[i] - gens[i-1], Ns[i]))\n",
    "epoques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_coal(g, N):\n",
    "    return 2*N - (g * np.exp(-g/(2*N))) / (1 - np.exp(-g/(2*N)))\n",
    "\n",
    "def epoch(demog, h, i):\n",
    "    g, N = demog[i]\n",
    "    N *= h\n",
    "    if i == len(demog)-1:\n",
    "        return 2*N\n",
    "    return (1-np.exp(-g/(2*N))) * exp_coal(g, N) + np.exp(-g/(2*N)) * (g + epoch(demog, h, i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few sanity checks on the demography:\n",
    "\n",
    "Make sure the demography produces the non-African X/A pi when we assume that African X/A pi reflects X/A Ne. Reading off from the plot in Mallick et al., the African X/A pi is 0.66 and the non-African one is 0.55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoques = [(x, y*1.15) for x, y in epoques]\n",
    "# epoques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch(epoques, 0.66, 0) / epoch(epoques, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems ok. We also want the actual values of non-African X pi to match the one produced by the demography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2 * 1.2e-8 * epoch(epoques, 0.66, 0), nonafr_mean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a neutral scenario, the demography should also produce the within-region pi of non-Africans from the within-region pi in Africans.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 1.2e-8 * epoch(epoques, 0.66*0.73, 0), nonafr_mean_dist_in_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That actually seems to be roughly the case. - Suggesting that a neutral scenario could indeed produce the observed pi values.\n",
    "\n",
    "To see if it may also produce the ECHs, we need to perform the sumulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that the ratio in africa outside regions fit observed X/A in in non-africans using pool-nielsen. That serves as a sanity check that the demography model is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 1.2e-8 * epoch(epoques, african_x_auto_ratio, 0), nonafr_mean_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to fit what they find in Mallick et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then if I take into account the lower Ne in region in africans, I get:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(what is the lowest possible X/A ratio? 0.5?)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epoques = [(1000, 1000), (1000, 1000), (1000, 1000), (1000, 1000), (None, 1000)]\n",
    "\n",
    "african_x_auto_ratio = 0.66 * 0.73\n",
    "pool_nielsen_ratio = epoch(epoques, african_x_auto_ratio, 0) / epoch(epoques, 1, 0)\n",
    "african_x_auto_ratio, pool_nielsen_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 * 1.2e-8 * epoch(epoques, african_x_auto_ratio, 0), nonafr_mean_dist_in_regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does that square with the empirical pi values and X/A values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0.001, 1, 100)\n",
    "y = [epoch(epoques, h, 0) / epoch(epoques, 1, 0) for h in x]\n",
    "plt.plot(x, y) ;\n",
    "plt.axvline(african_x_auto_ratio, color='black', linestyle='dashed')\n",
    "plt.axhline(pool_nielsen_ratio, color='black', linestyle='dashed') ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lift over regions to hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_peak_regions_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extended_peak_regions_10.loc[lambda df: df.peak_prop_swept >= 0.5, \n",
    "                                   ['chrom', 'start_pos', 'end_pos']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifted = '''\n",
    "chrX\t19281882\t20581882\tchrX:19300001-20600000\t1\n",
    "chrX\t20481882\t21681882\tchrX:20500001-21700000\t1\n",
    "chrX\t35681883\t37080183\tchrX:35700001-37100000\t1\n",
    "chrX\t37340747\t37940747\tchrX:37200001-37800000\t1\n",
    "chrX\t50057375\t50057403\tchrX:49400001-50300000\t1\n",
    "chrX\t53373079\t54873567\tchrX:53400001-54900000\t1\n",
    "chrX\t63280123\t64680120\tchrX:62500001-63900000\t1\n",
    "chrX\t64580120\t66080158\tchrX:63800001-65300000\t1\n",
    "chrX\t73080161\t74380165\tchrX:72300001-73600000\t1\n",
    "chrX\t74480165\t75680165\tchrX:73700001-74900000\t1\n",
    "chrX\t77448201\t78544503\tchrX:76700001-77800000\t1\n",
    "chrX\t98945002\t100145002\tchrX:98200001-99400000\t1\n",
    "chrX\t109856771\t112356772\tchrX:109100001-111600000\t1\n",
    "chrX\t114365547\t115465284\tchrX:113600001-114700000\t1\n",
    "chrX\t78550431\t78550462\tchrX:113600001-114700000\t2\n",
    "chrX\t114761888\t114761918\tchrX:113600001-114700000\t3\n",
    "chrX\t114761888\t114761980\tchrX:113600001-114700000\t4\n",
    "chr17\t60552205\t60552228\tchrX:113600001-114700000\t5\n",
    "chrX\t126866017\t128566022\tchrX:126000001-127700000\t1\n",
    "chrX\t130366026\t131066026\tchrX:129500001-130200000\t1\n",
    "chrX\t131865972\t132665972\tchrX:131000001-131800000\t1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extended_peak_regions_10[['chrom', 'start_pos', 'end_pos']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used online liftover to convert to hg38 allowing, checking box to allow multiple output regions. Pasted in below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifted = '''\n",
    "chrX\t10781881\t11681880\tchrX:10800001-11700000\t1\n",
    "chrX\t14181878\t15181878\tchrX:14200001-15200000\t1\n",
    "chrX\t19281882\t20581882\tchrX:19300001-20600000\t1\n",
    "chrX\t20481882\t21681882\tchrX:20500001-21700000\t1\n",
    "chrX\t35681883\t37080183\tchrX:35700001-37100000\t1\n",
    "chrX\t37340747\t37940747\tchrX:37200001-37800000\t1\n",
    "chrX\t43140751\t43740753\tchrX:43000001-43600000\t1\n",
    "chrX\t50057375\t50057403\tchrX:49400001-50300000\t1\n",
    "chrX\t50957000\t51657066\tchrX:50700001-51400000\t1\n",
    "chr2\t33174181\t33174306\tchrX:50700001-51400000\t2\n",
    "chrX\t53373079\t54873567\tchrX:53400001-54900000\t1\n",
    "chrX\t54973567\t56273567\tchrX:55000001-56300000\t1\n",
    "chrX\t63280123\t64680120\tchrX:62500001-63900000\t1\n",
    "chrX\t64580120\t66080158\tchrX:63800001-65300000\t1\n",
    "chrX\t67280158\t68180158\tchrX:66500001-67400000\t1\n",
    "chrX\t68080158\t68680158\tchrX:67300001-67900000\t1\n",
    "chrX\t73080161\t74380165\tchrX:72300001-73600000\t1\n",
    "chrX\t74480165\t75680165\tchrX:73700001-74900000\t1\n",
    "chrX\t77448201\t78544503\tchrX:76700001-77800000\t1\n",
    "chrX\t98945002\t100145002\tchrX:98200001-99400000\t1\n",
    "chrX\t101545013\t102145028\tchrX:100800001-101400000\t1\n",
    "chrX\t105255317\t106056009\tchrX:104500001-105300000\t1\n",
    "chrX\t107056770\t108256770\tchrX:106300001-107500000\t1\n",
    "chrX\t109856771\t112356772\tchrX:109100001-111600000\t1\n",
    "chrX\t114365547\t115465284\tchrX:113600001-114700000\t1\n",
    "chrX\t78550431\t78550462\tchrX:113600001-114700000\t2\n",
    "chrX\t114761888\t114761918\tchrX:113600001-114700000\t3\n",
    "chrX\t114761888\t114761980\tchrX:113600001-114700000\t4\n",
    "chr17\t60552205\t60552228\tchrX:113600001-114700000\t5\n",
    "chrX\t126866017\t128566022\tchrX:126000001-127700000\t1\n",
    "chrX\t130366026\t131066026\tchrX:129500001-130200000\t1\n",
    "chrX\t131865972\t132665972\tchrX:131000001-131800000\t1\n",
    "chrX\t133165972\t134465970\tchrX:132300001-133600000\t1\n",
    "chrX\t154671726\t155270710\tchrX:153900001-154500000\t1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant recombination rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for row in lifted.strip().split('\\n'):\n",
    "    records.append([x.isdigit() and int(x) or x for x in row.split()])\n",
    "extended_peak_regions_10_hg38 = pd.DataFrame.from_records(records, \n",
    "                                    columns=['chrom', 'start', 'end', 'segment', 'piece'])\n",
    "extended_peak_regions_10_hg38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_maternal = pd.read_table(ag.data_dir / 'decode_hg38_maternal.tsv', comment='#')\n",
    "decode_maternal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean rate for entire chromosome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_maternal_chrX = decode_maternal.loc[decode_maternal['Chr'] == 'chrX']\n",
    "mean_maternal_rate = np.average(decode_maternal_chrX.cMperMb, weights=decode_maternal_chrX.End-decode_maternal_chrX.Begin)\n",
    "mean_maternal_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list()\n",
    "for tup in extended_peak_regions_10_hg38.itertuples():\n",
    "    lst.append(decode_maternal_chrX.loc[(decode_maternal_chrX.Begin >= tup.start) & \\\n",
    "                                         (decode_maternal_chrX.End <= tup.end)])\n",
    "df = pd.concat(lst).assign(length=lambda df: df.End-df.Begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = 0\n",
    "# for tup in df.itertuples():\n",
    "#     x += tup.length / tup.cMperMb\n",
    "# df.cMperMb.sum() / x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_rates = list()\n",
    "for tup in extended_peak_regions_10_hg38.itertuples():\n",
    "    df = decode_maternal_chrX.loc[(decode_maternal_chrX.Begin >= tup.start) & \\\n",
    "                                         (decode_maternal_chrX.End <= tup.end)]\n",
    "    try:\n",
    "        print(np.average(df.cMperMb, weights=df.End-df.Begin), (df.End-df.Begin).sum())\n",
    "    except:\n",
    "        print('no data')\n",
    "    region_rates.append(df.cMperMb.mean())\n",
    "#region_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per-generation recombination rate for all the regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = list()\n",
    "for tup in extended_peak_regions_10_hg38.itertuples():\n",
    "    df_list.append(decode_maternal_chrX.loc[(decode_maternal_chrX.Begin >= tup.start) & (decode_maternal_chrX.End <= tup.end)])\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_peak_regions_10_mean_rate = np.average(df.cMperMb, weights=df.End-df.Begin)\n",
    "extended_peak_regions_10_mean_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean per-meiosis recombination rate for all the regions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_peak_regions_10_mean_rate * 3 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data for sweeps called on simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_swept_data = pd.read_hdf(str(ag.steps_dir / 'slim' / 'slim_summary.hdf'))\n",
    "prop_swept_data['prop_swept'] = prop_swept_data.nr_swept / prop_swept_data.total\n",
    "prop_swept_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = list()\n",
    "for demog, x_auto_ratio, rec_rate_per_gen, chrom, sweep_type, sweep_start in prop_swept_data.simulation.str.split('_'):\n",
    "    records.append([demog, int(x_auto_ratio)/100, int(rec_rate_per_gen)/1e-12, chrom, sweep_type, int(sweep_start)])\n",
    "\n",
    "df = pd.DataFrame.from_records(records, \n",
    "                      columns=['demography', 'x_auto_ratio', 'rec_rate_per_gen', \n",
    "                               'chrom', 'sweep_type', 'sweep_start'], \n",
    "                              )\n",
    "\n",
    "# df = pd.DataFrame.from_records(records, \n",
    "#                       columns=['sweep_type', 'N', 'bottle_start', 'bottle_end', 'bottle_width', 'sweep_start'], \n",
    "#                               )\n",
    "# df['bottle_width'] = df.bottle_end - df.bottle_start\n",
    "prop_swept_data = prop_swept_data.merge(df, left_index=True, right_index=True)\n",
    "prop_swept_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def facet_plot(start, end, prop_swept, **kwargs):\n",
    "    x = [j for i in zip(start, end) for j in i]\n",
    "    y = [j for i in zip(prop_swept, prop_swept) for j in i]      \n",
    "    plt.plot(x, y, color='black', linewidth=0.2)\n",
    "#    plt.plot(x, y, linewidth=0.2, **kwargs)\n",
    "    plt.ylim((0, 1.1))\n",
    "    plt.fill_between(x, 0, y, color='gray', alpha=0.05)\n",
    "\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "#     g = sns.FacetGrid(prop_swept_data, col='simulation', row='selection_coef', \n",
    "    g = sns.FacetGrid(prop_swept_data, col='selection_coef', row='simulation', \n",
    "                      hue='replication', sharex=True, sharey=True, margin_titles=True,\n",
    "                     height=2, aspect=5)\n",
    "    g.map(facet_plot, 'start', 'end', 'prop_swept')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, text=\"\") # remove the original texts, important to do this before setting titles\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, rotation=\"0\") # remove the original texts, important to do this before setting titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with sns.axes_style('whitegrid'):\n",
    "#     g = sns.FacetGrid(prop_swept_data, col='simulation', row='selection_coef', \n",
    "    g = sns.FacetGrid(prop_swept_data.loc[prop_swept_data.simulation.str.startswith('standard_40_4650')],\n",
    "                      col='selection_coef', row='simulation', \n",
    "                      hue='replication', sharex=True, sharey=True, margin_titles=True,\n",
    "                     height=3, aspect=5)\n",
    "    g.map(facet_plot, 'start', 'end', 'prop_swept')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, text=\"\") # remove the original texts, important to do this before setting titles\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, rotation=\"0\") # remove the original texts, important to do this before setting titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_swept_data.simulation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def facet_plot(start, end, prop_swept, **kwargs):\n",
    "    x = [j for i in zip(start, end) for j in i]\n",
    "    y = [j for i in zip(prop_swept, prop_swept) for j in i]      \n",
    "    plt.plot(x, y, color='black', linewidth=0.2)\n",
    "#    plt.plot(x, y, linewidth=0.2, **kwargs)\n",
    "    plt.ylim((0, 1))\n",
    "    plt.fill_between(x, 0, y, color='gray', alpha=0.5)\n",
    "\n",
    "with sns.axes_style('whitegrid'):\n",
    "#     g = sns.FacetGrid(prop_swept_data, col='simulation', row='selection_coef', \n",
    "    g = sns.FacetGrid(prop_swept_data.loc[prop_swept_data.simulation.isin(['standard_55_4650_X_nosweep_98275',\n",
    "                                                                          'standard_40_4650_X_nosweep_98275',\n",
    "                                                                          'standard_48_4650_X_nosweep_98275',\n",
    "                                                                          'standard_66_4650_X_nosweep_98275'])],\n",
    "                      col='replication', row='simulation', sharex=True, sharey=True, margin_titles=True,\n",
    "                     height=4, aspect=0.5)\n",
    "    g.map(facet_plot, 'start', 'end', 'prop_swept')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, text=\"\") # remove the original texts, important to do this before setting titles\n",
    "    g.set_titles(row_template = '{row_name}', col_template = '{col_name}')\n",
    "\n",
    "    for ax in g.axes.flat:\n",
    "        plt.setp(ax.texts, rotation=\"0\") # remove the original texts, important to do this before setting titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(str(ag.steps_dir / 'slim/simulations/standard/66/4650/X/nosweep/98275/10/standard_66_4650_X_nosweep_98275_10_0.hdf'))\n",
    "\n",
    "plt.hist(df.dist, bins=100, alpha=0.5) ;\n",
    "plt.axvline(5e-5, color='orange', linestyle='dashed') ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(str(ag.steps_dir / 'slim/simulations/standard/48/4650/X/nosweep/98275/10/standard_48_4650_X_nosweep_98275_10_0.hdf'))\n",
    "\n",
    "plt.hist(df.dist, bins=100, alpha=0.5) ;\n",
    "plt.axvline(5e-5, color='orange', linestyle='dashed');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = 'standard_40_4650_X_nosweep_98275_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=200, alpha=0.5) ;\n",
    "\n",
    "# s = 'standard_40_4650_X_nosweep_98275_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=200, alpha=0.5) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = 'nosweep_10000_96551_98965_10000_96206_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=200, alpha=0.5) ;\n",
    "\n",
    "# s = 'nosweep_10000_96551_98965_1000_96206_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=200, alpha=0.5) ;\n",
    "\n",
    "# s = 'nosweep_10000_96954_98563_690_98275_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=200, alpha=0.5) ;\n",
    "\n",
    "# s = 'nosweep_10000_97356_98160_357_99310_{}'.format(20)\n",
    "# f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "# df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "# plt.hist(df.dist, bins=100, alpha=0.5) ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "s = 'nosweep_10000_3448_5861_10000_5171_{}'.format(20)\n",
    "f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "plt.hist(df.dist, bins=100, alpha=0.5) ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'nosweep_10000_3447_5861_1000_3102_{}'.format(20)\n",
    "f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "plt.hist(df.dist, bins=200, alpha=0.5) ;\n",
    "\n",
    "s = 'nosweep_10000_3448_5861_10000_3102_{}'.format(20)\n",
    "f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "plt.hist(df.dist, bins=200, alpha=0.5) ;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'nosweep_10000_3447_5861_1000_3102_{}'.format(20)\n",
    "f_name_tmpl = '/home/kmt/simons/faststorage/people/kmt/steps/slim/simulations/' + s.replace('_', '/') + '/{}_{{}}.hdf'.format(s)\n",
    "df = pd.read_hdf(f_name_tmpl.format(0))\n",
    "plt.hist(df.dist, bins=100) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    df = pd.read_hdf(f_name_tmpl.format(i))\n",
    "    plt.hist(df.dist, bins=100)\n",
    "    plt.axvline(5e-5, color='orange', zorder=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyslim, msprime, random\n",
    "seed = 7\n",
    "mutation_rate = 1.25e-8\n",
    "sample_size = 100\n",
    "\n",
    "trees = pyslim.load(f_name_tmpl.format(0).replace('.hdf', '.trees'))\n",
    "\n",
    "# Overlay neutral mutations and make bit arrays for each SNP:\n",
    "sample_ids = sorted(random.sample(list(trees.samples()), sample_size))\n",
    "\n",
    "trees_sample = trees.simplify(samples=sample_ids, filter_zero_mutation_sites=True, filter_individuals=True)\n",
    "mutated_trees = msprime.mutate(trees_sample, rate=mutation_rate, random_seed=seed)\n",
    "# mutated.dump(\"./sweep_overlaid.trees\") \n",
    "print(mutated_trees.pairwise_diversity() / mutated_trees.sequence_length)\n",
    "\n",
    "\n",
    "ts = mutated_trees\n",
    "# Measure the tree height at each base position\n",
    "height_for_pos = np.zeros(int(ts.sequence_length))\n",
    "for tree in ts.trees():\n",
    "    mean_height = np.mean([tree.time(root) for root in tree.roots])\n",
    "    left, right = map(int, tree.interval)\n",
    "    height_for_pos[left: right] = mean_height\n",
    "height_for_pos\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(height_for_pos, linewidth=0.5, color='black') ;\n",
    "\n",
    "\n",
    "trees = pyslim.load(f_name_tmpl.format(1).replace('.hdf', '.trees'))\n",
    "\n",
    "# Overlay neutral mutations and make bit arrays for each SNP:\n",
    "sample_ids = sorted(random.sample(list(trees.samples()), sample_size))\n",
    "\n",
    "trees_sample = trees.simplify(samples=sample_ids, filter_zero_mutation_sites=True, filter_individuals=True)\n",
    "mutated_trees = msprime.mutate(trees_sample, rate=mutation_rate, random_seed=seed)\n",
    "# mutated.dump(\"./sweep_overlaid.trees\") \n",
    "print(mutated_trees.pairwise_diversity() / mutated_trees.sequence_length)\n",
    "\n",
    "\n",
    "ts = mutated_trees\n",
    "# Measure the tree height at each base position\n",
    "height_for_pos = np.zeros(int(ts.sequence_length))\n",
    "for tree in ts.trees():\n",
    "    mean_height = np.mean([tree.time(root) for root in tree.roots])\n",
    "    left, right = map(int, tree.interval)\n",
    "    height_for_pos[left: right] = mean_height\n",
    "height_for_pos\n",
    "\n",
    "plt.plot(height_for_pos, linewidth=0.5, color='red') ;\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run slim testing to get pairwise distances for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import argparse\n",
    "import random\n",
    "import subprocess\n",
    "import re, os, sys\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import msprime, pyslim\n",
    "\n",
    "trees_file = \"/home/kmt/simons/faststorage/people/kmt/test_slim.trees\"\n",
    "\n",
    "slurm_script = r'''\n",
    "initialize() {\n",
    "\tinitializeTreeSeq();\n",
    "\tinitializeMutationRate(0);\n",
    "\tinitializeMutationType(\"m1\", 0.5, \"f\", 0.0);\n",
    "\tinitializeGenomicElementType(\"g1\", m1, 1.0);\n",
    "\tinitializeGenomicElement(g1, 0, 10e6-1);\n",
    "\tinitializeRecombinationRate(1e-8);\n",
    "}\n",
    "1 {\n",
    "\tdefineConstant(\"simID\", getSeed());\n",
    "\tsim.addSubpop(\"p1\", 10000);\n",
    "}\n",
    "50000 {\n",
    "    sim.treeSeqOutput(\"OUTFILE\");\n",
    "\tsim.simulationFinished();\n",
    "}\n",
    "'''.replace('OUTFILE', trees_file)\n",
    "\n",
    "print(slurm_script)\n",
    "random.seed(7)\n",
    "\n",
    "window_size = 100000\n",
    "\n",
    "# write slim script file with the right output name\n",
    "slurm_script_file = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "slurm_script_file.write(slurm_script)\n",
    "slurm_script_file.close()\n",
    "\n",
    "# run slim\n",
    "cmd = '/home/kmt/simons/faststorage/people/kmt/slim {}'.format(slurm_script_file.name)\n",
    "p = subprocess.Popen(cmd.split(), \n",
    "    stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "stdout, stderr = p.communicate()\n",
    "print(stdout.decode())\n",
    "print(stderr.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutationrate = 4.3e-10\n",
    "generationtime = 29\n",
    "\n",
    "# load trees from slim\n",
    "ts = pyslim.load(trees_file)\n",
    "\n",
    "# overlay mutations\n",
    "mutated_ts = msprime.mutate(ts, rate=mutationrate*generationtime, random_seed=2, keep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = mutated_trees\n",
    "# Measure the tree height at each base position\n",
    "height_for_pos = np.zeros(int(ts.sequence_length))\n",
    "for tree in ts.trees():\n",
    "    mean_height = np.mean([tree.time(root) for root in tree.roots])\n",
    "    left, right = map(int, tree.interval)\n",
    "    height_for_pos[left: right] = mean_height\n",
    "height_for_pos\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.plot(height_for_pos, linewidth=0.5, color='black') ;\n",
    "\n",
    "height_for_pos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 10\n",
    "\n",
    "# random indexes for samples\n",
    "sample_idx = set(random.sample(range(ts.num_individuals), samples))\n",
    "assert len(sample_idx) == samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the corresponding sample haplotypes\n",
    "sample = list()\n",
    "for i, hap in enumerate(mutated_ts.haplotypes()):\n",
    "    if i in sample_idx:\n",
    "        sample.append(hap)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# get the positions of each segregating site\n",
    "positions = [site.position for site in mutated_ts.sites()]  \n",
    "\n",
    "# make table with sampled haplotypes\n",
    "table = np.array([list(map(np.int8, hap)) for hap in sample]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn table into dataframe with positions\n",
    "df = DataFrame(table, dtype='int8')\n",
    "df['pos'] = positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a row with zeros for the start of each window so there is at least\n",
    "# one row in each window\n",
    "zeros = dict((x, 0) for x in range(samples))\n",
    "extra_df = pd.DataFrame({'pos': range(0, int(mutated_ts.sequence_length), window_size), **zeros})\n",
    "df = df.append(extra_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a start column grouping all rows in same window\n",
    "df['start'] = ((df.pos // window_size) * window_size).astype('uint32')\n",
    "df.drop('pos', axis=1, inplace=True)\n",
    "df.set_index('start', inplace=True)\n",
    "\n",
    "def pw_dist(df):\n",
    "    \"computes differences bewteen all pairs in a window\"\n",
    "    pairs = list(combinations(df.columns, 2))\n",
    "    site_diffs = [np.bitwise_xor(df[p[0]], df[p[1]]) for p in pairs]\n",
    "    return pd.concat(site_diffs, axis=1, keys=pairs).sum()\n",
    "\n",
    "# make a dataframe with distance for each pair\n",
    "pw_dist_df = (\n",
    "    df\n",
    "    .groupby('start')\n",
    "    .apply(pw_dist)\n",
    "    .reset_index()\n",
    "    .melt(id_vars=['start'], var_name=['indiv_1', 'indiv_2'], value_name='dist')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute proper distance as number of diffs divided by window size\n",
    "pw_dist_df['dist'] /= window_size\n",
    "\n",
    "# add end column\n",
    "pw_dist_df.insert(loc=1, column='end', value=pw_dist_df.start + window_size)\n",
    "\n",
    "# convert indiv labels from object to int and and write hdf\n",
    "pw_dist_df['indiv_1'] = pw_dist_df['indiv_1'].astype('uint16')\n",
    "pw_dist_df['indiv_2'] = pw_dist_df['indiv_2'].astype('uint16')\n",
    "#pw_dist_df.to_hdf(args.hdf_file, 'df', format='table', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pw_dist_df.dist) \n",
    "plt.axvline(5e-5, color='orange') ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
