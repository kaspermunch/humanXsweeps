{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Make inline plots vector graphics instead of raster graphics\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('pdf', 'svg')\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "import mpld3\n",
    "\n",
    "class d3(object):\n",
    "    \"\"\"with statement for d3 in only one plot\"\"\"\n",
    "\n",
    "    def __enter__(self):\n",
    "        mpld3.enable_notebook()\n",
    "\n",
    "    def __exit__(self ,type, value, traceback):\n",
    "        mpld3.disable_notebook()\n",
    "\n",
    "        \n",
    "class Swap(object):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        pass\n",
    "        \n",
    "        \n",
    "class SwapPalette(Swap):\n",
    " \n",
    "# Actually not required. you can just do this:\n",
    "# with sns.color_palette(\"PuBuGn_d\"):\n",
    "#     sinplot()  \n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.orig = sns.color_palette()\n",
    "        sns.set_palette(*self.args, **self.kwargs)\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        sns.set_palette(self.orig)\n",
    "\n",
    "        \n",
    "class SwapStyle(Swap):\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.orig = sns.axes_style()\n",
    "        sns.set_style(*self.args, **self.kwargs)\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        sns.set_style(self.orig)\n",
    "\n",
    "        \n",
    "class SwapContext(Swap):\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.orig = sns.plotting_context()\n",
    "        sns.set_context(*self.args, **self.kwargs)\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        sns.set_style(self.orig)\n",
    "\n",
    "        \n",
    "class Timer(object):\n",
    "    \n",
    "    def __init__(self, verbose=True):\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.end = time.time()\n",
    "        self.secs = self.end - self.start\n",
    "        if self.verbose:\n",
    "            print('elapsed time: {} secs'.format(self.secs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem with Crete ? ?\n",
      "problem with Crete ? ?\n",
      "problem with Australian .. ..\n",
      "problem with Norwegian .. ..\n",
      "problem with Balochi .. ..\n",
      "problem with Bergamo .. ..\n",
      "['Mozabite', 'Esan', 'Masai', 'Mbuti', 'Mende', 'Biaka', 'Mandenka', 'Dinka', 'Yoruba', 'Luhya', 'Khomani_San', 'BantuTswana', 'BantuKenya', 'BantuHerero', 'Ju_hoan_North', 'Saharawi', 'Somali', 'Luo', 'Gambian', 'Saami', 'Norwegian', 'Hungarian', 'Finnish', 'Lezgin', 'Crete', 'Armenian', 'Bergamo', 'Icelandic', 'North_Ossetian', 'Tuscan', 'Iraqi_Jew', 'Iranian', 'Jordanian', 'Tajik', 'Spanish', 'Abkhasian', 'Adygei', 'Czech', 'Georgian', 'Bulgarian', 'Basque', 'French', 'Yemenite_Jew', 'Druze', 'Russian', 'Samaritan', 'Sardinian', 'Greek', 'Polish', 'Turkish', 'Estonian', 'Albanian', 'BedouinB', 'Palestinian', 'English', 'Orcadian', 'Chechen', 'Ulchi', 'Kyrgyz', 'Tubalar', 'Eskimo_Chaplin', 'Eskimo_Sireniki', 'Altaian', 'Tlingit', 'Mansi', 'Mongola', 'Even', 'Yakut', 'Eskimo_Naukan', 'Chukchi', 'Itelman', 'Aleut', 'Kalash', 'Khonda_Dora', 'Mala', 'Pathan', 'Sindhi', 'Makrani', 'Balochi', 'Brahmin', 'Brahui', 'Burusho', 'Kapu', 'Bengali', 'Yadava', 'Madiga', 'Irula', 'Hazara', 'Kusunda', 'Relli', 'Punjabi', 'Hawaiian', 'Australian', 'Igorot', 'Maori', 'Dusun', 'Papuan', 'Bougainville', 'Ami', 'Kinh', 'Oroqen', 'Dai', 'Daur', 'Naxi', 'Korean', 'Atayal', 'Yi', 'Tu', 'Han', 'Japanese', 'Uygur', 'She', 'Thai', 'Miao', 'Lahu', 'Cambodian', 'Xibo', 'Tujia', 'Hezhen', 'Burmese', 'Mayan', 'Karitiana', 'Surui', 'Mixtec', 'Piapoco', 'Zapotec', 'Quechua', 'Chane', 'Mixe', 'Pima']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from math import sin, cos, sqrt, atan2, pi\n",
    "\n",
    "# read in meta data to get sex of each individual\n",
    "def get_meta_data():\n",
    "\n",
    "    meta_data_file_name = os.path.join('data', 'nature18964-s2-fixed-genders.csv')\n",
    "    meta_data = dict()\n",
    "    with open(meta_data_file_name, 'r') as f:\n",
    "        keys = f.readline().split(';')\n",
    "        for l in f:\n",
    "            d = dict(zip(keys, l.split(';')))\n",
    "            if d['Embargo level (X=Fully Public, Y=Signed Letter)'] == 'X':\n",
    "                meta_data[d['Sample ID (SGDP)']] = d\n",
    "\n",
    "    # dicts of samples from each population and region\n",
    "    populations = defaultdict(list)\n",
    "    regions = defaultdict(list)\n",
    "    for key in meta_data:\n",
    "        pop = meta_data[key]['Population ID']\n",
    "        populations[pop].append(key)\n",
    "\n",
    "        reg = meta_data[key]['Region']\n",
    "        regions[reg].append(key)\n",
    "\n",
    "    return meta_data, populations, regions\n",
    "\n",
    "simons_meta_data, simons_populations, simons_regions = get_meta_data()\n",
    "\n",
    "simons_pop_locations = dict()\n",
    "for pop in simons_populations:\n",
    "    for indiv in simons_populations[pop]:\n",
    "        try:\n",
    "            lat = float(simons_meta_data[indiv]['Latitude'].replace(',', '.'))\n",
    "            long = float(simons_meta_data[indiv]['Longitude'].replace(',', '.'))\n",
    "        except ValueError:\n",
    "            print(\"problem with\", pop, simons_meta_data[indiv]['Latitude'], simons_meta_data[indiv]['Longitude'])\n",
    "            continue\n",
    "        if pop not in simons_pop_locations:\n",
    "            simons_pop_locations[pop] = []\n",
    "        simons_pop_locations[pop].append((lat, long))\n",
    "\n",
    "def center_geo(latitudes, longitudes):\n",
    "\n",
    "    lat_list, lon_list = list(latitudes), list(longitudes)\n",
    "    \n",
    "    x_list = [cos(lat * pi/180 ) * cos(lon * pi/180 ) for lat, lon in zip(lat_list, lon_list)]\n",
    "    y_list = [cos(lat * pi/180 ) * sin(lon * pi/180 ) for lat, lon in zip(lat_list, lon_list)]\n",
    "    z_list = [sin(lat * pi/180 ) for lat in lat_list]\n",
    "    \n",
    "    x = sum(x_list)/len(x_list)\n",
    "    y = sum(y_list)/len(y_list)\n",
    "    z = sum(z_list)/len(z_list)\n",
    "\n",
    "    center_long = atan2(y, x)  * 180 / pi\n",
    "    hyp = sqrt(x * x + y * y)\n",
    "    center_lat = atan2(z, hyp)  * 180 / pi\n",
    "    \n",
    "    return center_lat, center_long\n",
    "    \n",
    "              \n",
    "for pop in simons_pop_locations:    \n",
    "    simons_pop_locations[pop] = center_geo(*zip(*simons_pop_locations[pop]))\n",
    "              \n",
    "              \n",
    "# populations sorted by main region:\n",
    "regions = ['Africa', 'WestEurasia', 'CentralAsiaSiberia', 'SouthAsia', 'Oceania', 'EastAsia', 'America']\n",
    "sorted_simons_populations = list()\n",
    "for region in regions:\n",
    "    region_pops = list(set(x.split('-')[0][2:] for x in simons_regions[region]))\n",
    "    sorted_simons_populations.extend(region_pops)\n",
    "print(sorted_simons_populations)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_column_multi_index(df):\n",
    "    df.columns = ['_'.join(col).strip() for col in df.columns.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>pos</th>\n",
       "      <th>species</th>\n",
       "      <th>popu</th>\n",
       "      <th>pi_mean</th>\n",
       "      <th>is_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Australian</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Crete</td>\n",
       "      <td>0.006075</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Abkhasian</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Adygei</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>Aleut</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr  pos species        popu   pi_mean is_low\n",
       "0   X  1.0       H  Australian  0.004253  False\n",
       "1   X  1.0       H       Crete  0.006075  False\n",
       "2   X  1.0       H   Abkhasian  0.003978  False\n",
       "3   X  1.0       H      Adygei  0.004770  False\n",
       "4   X  1.0       H       Aleut  0.003337  False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = ['chr', 'pos', 'end', 'popu', 'ind1', 'ind2', 'sex2', 'sex2', 'diffs', 'total']\n",
    "mask = lambda x: np.where(x.total > 30000)\n",
    "df = (pd.read_table('data/simons_pi_data_x.tsv', names=colnames)\n",
    "      .assign(pi = lambda x: x.diffs / x.total)\n",
    "      .assign(species = 'H')\n",
    "      .loc[mask]\n",
    "     )[['chr', 'pos', 'species', 'popu', 'pi']]\n",
    "df = (df\n",
    "      .groupby(['chr', 'pos', 'species', 'popu'])\n",
    "      .aggregate([np.mean])\n",
    "     )\n",
    "flatten_column_multi_index(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "simons_pi_data = (df\n",
    "                  .reset_index()\n",
    "                  .assign(is_low = lambda x: x.pi_mean < np.mean(x.pi_mean) * 0.05)#0.0002)\n",
    "                 )\n",
    "simons_pi_data['pos'] /= 100000\n",
    "\n",
    "simons_pi_data['popu'] = [x.split('_')[1] for x in simons_pi_data['popu']]\n",
    "\n",
    "simons_pi_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bar  baz chrom  end  foo  start value\n",
      "0     9    4  chr1    5    7      0   AAA\n",
      "1     9    4  chr2    2    7      1   AAA\n",
      "2     9    4  chr2    7    7      2   AAA\n",
      "3     9    4  chr2    4    7      3   AAA\n",
      "4     9    4  chr2    9    7      4   AAA\n",
      "5     9    4  chr2    6    7      5   AAA\n",
      "6     9    4  chr2   11    7      6   AAA\n",
      "7     9    4  chr2    8    7      7   AAA\n",
      "8     9    4  chr2   13    7      8   AAA\n",
      "9     9    4  chr2   10    7      9   AAA\n",
      "10    9    4  chr2   30    7     10   AAA\n",
      "             start  end  count1\n",
      "chrom bar                      \n",
      "chr1  9   0      0    5       1\n",
      "chr2  9   0      0    5       4\n",
      "          1      5   10       7\n",
      "          2     10   15       3\n",
      "          3     15   20       1\n",
      "          4     20   25       1\n",
      "          5     25   30       1\n",
      "         start  end  count1\n",
      "chrom                      \n",
      "chr1  0      0    5       1\n",
      "chr2  0      0    5       4\n",
      "      1      5   10       7\n",
      "      2     10   15       3\n",
      "      3     15   20       1\n",
      "      4     20   25       1\n",
      "      5     25   30       1\n",
      "         start   end  count2\n",
      "chrom                       \n",
      "chr1  0    0.0   2.0       1\n",
      "      1    2.0   4.0       1\n",
      "      2    4.0   8.0       1\n",
      "chr2  0    0.0   2.0       1\n",
      "      1    2.0   4.0       2\n",
      "      2    4.0   8.0       5\n",
      "      3    8.0  16.0       5\n",
      "      4   16.0  32.0       1\n",
      "         start  end  sum  count\n",
      "chrom                          \n",
      "chr1  0      0    5    5      1\n",
      "chr2  0      0    5    6      4\n",
      "      1      5    9   12      6\n",
      "      2      9   13   10      4\n",
      "      3     13   23   10      1\n",
      "      4     23   30    7      1\n",
      "             start  end  bar  foo\n",
      "chrom baz                        \n",
      "chr1  4   0      0    5    9    7\n",
      "chr2  4   0      0    5   36   28\n",
      "          1      5    9   54   42\n",
      "          2      9   13   36   28\n",
      "          3     13   23    9    7\n",
      "          4     23   30    9    7\n",
      "MultiIndex(levels=[['chr1', 'chr2'], [4], [0, 1, 2, 3, 4]],\n",
      "           labels=[[0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0], [0, 0, 1, 2, 3, 4]],\n",
      "           names=['chrom', 'baz', None])\n",
      "           start  end  bar  foo\n",
      "chrom baz                      \n",
      "chr1  4        0    5    9    7\n",
      "chr2  4        0    5   36   28\n",
      "      4        5    9   54   42\n",
      "      4        9   13   36   28\n",
      "      4       13   23    9    7\n",
      "      4       23   30    9    7\n",
      "MultiIndex(levels=[['chr1', 'chr2'], [4]],\n",
      "           labels=[[0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0]],\n",
      "           names=['chrom', 'baz'])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "\n",
    "from math import log\n",
    "from functools import wraps\n",
    "from operator import itemgetter\n",
    "from bisect import bisect\n",
    "import sys\n",
    "import pandas as pd\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "\n",
    "def even_windows(df, nrobs):\n",
    "\n",
    "    intervals = sorted((x.start, x.end) for x in full_df[['start', 'end']].itertuples())\n",
    "#    intervals = list(df[['start', 'end']].itertuples())\n",
    "    bins = list()\n",
    "\n",
    "    queue = list()\n",
    "    total = 0\n",
    "    i = 0 # interval index\n",
    "    pos = 0 # sequence index\n",
    "    prev_bin_end = 0\n",
    "\n",
    "    intervals_end = intervals[-1][1]\n",
    "    while pos < intervals_end:\n",
    "\n",
    "        # get any new intervals\n",
    "        while i < len(intervals) and pos == intervals[i][0]:\n",
    "            assert intervals[i][0] == int(intervals[i][0]), 'only ints please'\n",
    "            queue.insert(bisect(queue, intervals[i][1]), intervals[i][1]) # put the end in a sorted queue\n",
    "            i += 1\n",
    "\n",
    "        # remove intervals no longer overlapping:\n",
    "        while queue and queue[0] <= pos:\n",
    "            queue.pop(0)\n",
    "\n",
    "        # update running total\n",
    "        total += len(queue)\n",
    "\n",
    "        if total >= nrobs:\n",
    "            binsize = pos + 1 - prev_bin_end\n",
    "            bins.append(binsize)\n",
    "            prev_bin_end = pos + 1\n",
    "            total = 0\n",
    "\n",
    "        pos += 1\n",
    "\n",
    "    binsize = pos - prev_bin_end\n",
    "    bins.append(binsize)\n",
    "\n",
    "    return bins\n",
    "\n",
    "\n",
    "class Bin(object):\n",
    "    def __init__(self, binsize=None, logbase=1, bins=None):\n",
    "        self.bin_size = binsize\n",
    "        self.log_base = logbase\n",
    "        self.bin_list = bins\n",
    "        if self.bin_list is not None:\n",
    "            assert logbase == 1 and not binsize, \"Don't use bins with binsize or logbase\"\n",
    "            self.bin_list = bins[:]\n",
    "            self.bin_size = self.bin_list.pop(0)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.bin_start = 0\n",
    "        self.exhausted = False\n",
    "        return self\n",
    "    \n",
    "    def next(self):\n",
    "        next_bin = self.bin_start, self.bin_size\n",
    "        if self.bin_list is not None:\n",
    "            self.bin_start += self.bin_size\n",
    "            if self.bin_list:\n",
    "                self.bin_size = self.bin_list.pop(0)\n",
    "            else:\n",
    "                self.bin_size = float('inf')\n",
    "        elif self.log_base == 1 or self.bin_start == 0:\n",
    "            self.bin_start += self.bin_size\n",
    "\n",
    "        else:\n",
    "            prev_bin_size = self.bin_size\n",
    "            self.bin_size = self.log_base**(log(self.bin_size, self.log_base)+1)\n",
    "            self.bin_start += prev_bin_size\n",
    "        return next_bin\n",
    "\n",
    "    __next__ = next # Python 3.X compatibility\n",
    "\n",
    "\n",
    "def window(size=None, logbase=1, fixed=None, even=None):\n",
    "    def window_decorator(func):\n",
    "        @wraps(func)\n",
    "        def func_wrapper(full_df):\n",
    "\n",
    "            assert not(fixed and even), \"only fixed or even bins - not both\"\n",
    "            if even is None:\n",
    "                get_bin = iter(Bin(binsize=size, logbase=logbase, bins=fixed))\n",
    "            else:\n",
    "                get_bin = iter(Bin(binsize=size, logbase=logbase, bins=even_windows(full_df, even)))    \n",
    "            \n",
    "            bin_start, bin_size = get_bin.next()\n",
    "            \n",
    "            buf = list()\n",
    "            list_of_stat_results = list()\n",
    "\n",
    "            def process(buf):\n",
    "                df = pd.DataFrame(buf)\n",
    "                df.loc[df.start < bin_start, 'start'] = bin_start\n",
    "                df.loc[df.end > bin_start + bin_size, 'end'] = bin_start + bin_size\n",
    "                list_of_stat_results.append(([bin_start, bin_start + bin_size], func(df)))\n",
    "\n",
    "            for row_sr in full_df.itertuples():\n",
    "\n",
    "                while row_sr.start >= bin_start + bin_size:\n",
    "                    if buf:\n",
    "                        process(buf)\n",
    "                    bin_start, bin_size = get_bin.next()\n",
    "                    buf = [x for x in buf if x.end > bin_start]\n",
    "\n",
    "                buf.append(row_sr)\n",
    "\n",
    "            # empty buffer\n",
    "            while buf:\n",
    "                process(buf)\n",
    "                bin_start, bin_size = get_bin.next()\n",
    "                buf = [x for x in buf if x.end > bin_start]\n",
    "\n",
    "            # format output\n",
    "            def concat_dicts(l):\n",
    "                d = dict()\n",
    "                pairs = [b for a in zip(*[x.items() for x in l]) for b in a]\n",
    "                for k, v in pairs:\n",
    "                    d.setdefault(k, []).append(v)\n",
    "                return d                \n",
    "\n",
    "            coordinates, stats = zip(*list_of_stat_results)\n",
    "            if type(stats[0]) is dict:\n",
    "                d = OrderedDict(zip(('start', 'end'), zip(*coordinates)))\n",
    "                d.update(concat_dicts(stats))\n",
    "                return pd.DataFrame(d)#.drop([0], axis=1)\n",
    "\n",
    "            else:\n",
    "                return pd.DataFrame([x + [y] for x, y in list_of_stat_results],\n",
    "                                    columns=['start', 'end', func.__name__])\n",
    "        \n",
    "        return func_wrapper\n",
    "    return window_decorator\n",
    "\n",
    "\n",
    "def store_groupby_apply(store_file_name, col_names, fun, df_name='df', group_keys=True):\n",
    "\n",
    "    if type(col_names) is str:\n",
    "        col_names = [col_names]    \n",
    "        \n",
    "    with pd.get_store(store_file_name) as store:\n",
    "        groups = store.select(df_name, columns=col_names).drop_duplicates()\n",
    "        df_list = []\n",
    "        for tup in groups.itertuples():\n",
    "            mask = [\"{}={}\".format(col, getattr(tup, col)) for col in col_names]\n",
    "            grp_df = store.select(df_name, where = mask)\n",
    "            stats_df = fun(grp_df)            \n",
    "            if group_keys:\n",
    "                stats_df = (stats_df\n",
    "                            .assign(**dict((col, getattr(tup, col)) for col in col_names))\n",
    "                            .set_index(col_names)\n",
    "                            )\n",
    "            df_list.append(stats_df)\n",
    "\n",
    "    return pd.concat(df_list)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    full_df = pd.DataFrame({'chrom': ['chr1']+['chr2']*10, \n",
    "                        'start': list(range(11)), \n",
    "                        'end': list(map(sum, zip(range(11), [5, 1]*5+[20]))),\n",
    "                        'value': 'AAA',\n",
    "                       'foo': 7, 'bar': 9, 'baz' : 4})\n",
    "    print(full_df)\n",
    "    \n",
    "    # call this function windows of size 5\n",
    "    @window(size=5)\n",
    "    def count1(df):\n",
    "        return len(df.index)\n",
    "\n",
    "    print(full_df.groupby(['chrom', 'bar']).apply(count1))\n",
    "    #print(full_df.groupby(['chrom', 'bar']).apply(count1).reset_index())\n",
    "\n",
    "    print(full_df.groupby('chrom').apply(count1))#.reset_index())\n",
    "\n",
    "    # call this function on windows beginning at size 2 increasing by log 2\n",
    "    @window(size=2, logbase=2)\n",
    "    def count2(df):\n",
    "        return len(df.index)\n",
    "\n",
    "    print(full_df.groupby('chrom').apply(count2))#.reset_index(drop=True))\n",
    "\n",
    "    # call this function on windows with ~10 observations in each\n",
    "    @window(even=10)\n",
    "    def count3(df):\n",
    "        return {'count': len(df.index), 'sum': sum(df.end-df.start)}\n",
    "\n",
    "    print(full_df.groupby('chrom').apply(count3))#.reset_index(drop=True))\n",
    "\n",
    "    # call this function on windows with ~10 observations in each\n",
    "    @window(even=10)\n",
    "    def stats_fun(df):\n",
    "        sr = df[['foo','bar']].sum()\n",
    "        return sr.to_dict()\n",
    "\n",
    "    df = full_df.groupby(['chrom', 'baz']).apply(stats_fun)\n",
    "    print(df)\n",
    "    print(df.index)\n",
    "\n",
    "    # write the data frame to a hdf5 store\n",
    "    def write_df_store(df, store_file_name, df_name='df', table=True, append=False):\n",
    "        with pd.get_store(store_file_name) as store:\n",
    "            store.append(df_name, df, data_columns=list(df.columns.values), table=table, append=append)\n",
    "\n",
    "    write_df_store(full_df, 'groupby.h5')\n",
    "\n",
    "    # perform the same groupby and apply operation as on the data frame\n",
    "    df = store_groupby_apply('groupby.h5', ['chrom', 'baz'], stats_fun)\n",
    "    print(df)\n",
    "    print(df.index)\n",
    "    #print(df.reset_index())\n",
    "\n",
    "    \n",
    "    # next question: What happens when we group by the index (can we do that?) - and if so: should \n",
    "    # we then still add the \"groupby\" columns to the resulting dataframes?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"['Mozabite', 'Esan', 'Masai', 'Mbuti', 'Mende', 'Biaka', 'Mandenka', 'Dinka', 'Yoruba', 'Luhya', 'BantuTswana', 'BantuKenya', 'BantuHerero', 'Saharawi', 'Luo', 'Gambian', 'Saami', 'Hungarian', 'Finnish', 'Lezgin', 'Crete', 'Armenian', 'Bergamo', 'Icelandic', 'Tuscan', 'Iranian', 'Jordanian', 'Tajik', 'Spanish', 'Abkhasian', 'Adygei', 'Georgian', 'Bulgarian', 'Basque', 'French', 'Druze', 'Russian', 'Sardinian', 'Greek', 'Turkish', 'Estonian', 'BedouinB', 'Palestinian', 'English', 'Orcadian', 'Ulchi', 'Kyrgyz', 'Tubalar', 'Tlingit', 'Mansi', 'Mongola', 'Even', 'Yakut', 'Aleut', 'Kalash', 'Mala', 'Pathan', 'Sindhi', 'Makrani', 'Balochi', 'Brahmin', 'Brahui', 'Burusho', 'Kapu', 'Bengali', 'Yadava', 'Madiga', 'Irula', 'Hazara', 'Kusunda', 'Relli', 'Punjabi', 'Australian', 'Igorot', 'Dusun', 'Papuan', 'Bougainville', 'Ami', 'Kinh', 'Oroqen', 'Dai', 'Naxi', 'Korean', 'Yi', 'Tu', 'Han', 'Japanese', 'Uygur', 'She', 'Thai', 'Miao', 'Lahu', 'Cambodian', 'Xibo', 'Tujia', 'Hezhen', 'Burmese', 'Mayan', 'Karitiana', 'Surui', 'Mixtec', 'Piapoco', 'Zapotec', 'Quechua', 'Mixe', 'Pima']\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset of pops in this data set, in sorted order:\n",
    "pops_in_df = set(simons_pi_data_win.reset_index()['popu'])\n",
    "pop_sorting = [x for x in sorted_simons_populations if x in pops_in_df]\n",
    "print(len(pop_sorting), len(sorted_simons_populations))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   chrom            pi  pop  start\n",
      "0  chr11 -1.224647e-16  EUR      0\n",
      "1  chr11 -6.342392e-02  EUR      1\n",
      "2  chr11 -1.265925e-01  EUR      2\n",
      "3  chr11 -1.892512e-01  EUR      3\n",
      "4  chr11 -2.511480e-01  EUR      4\n",
      "elapsed time: 8.443495988845825 secs\n"
     ]
    }
   ],
   "source": [
    "def horizon_plot(df, key, width, cut=None, start='start', chrom='chrom', pop='pop', pop_sorting=None):\n",
    "    \"\"\"\n",
    "    Horizon bar plot made allowing multiple chromosomes and multiple samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    from math import isclose, floor, log10\n",
    "    \n",
    "    def horizon(row, i, cut):\n",
    "        \"\"\"\n",
    "        Compute the values for the three \n",
    "        positive and negative intervals.\n",
    "        \"\"\"\n",
    "        val = getattr(row, i)\n",
    "\n",
    "        if val < 0:\n",
    "            for i in range(4):\n",
    "                yield 0\n",
    "\n",
    "        val = abs(val)\n",
    "        for i in range(3):\n",
    "            yield min(cut, val)\n",
    "            val = max(0, val-cut)\n",
    "        yield int(not isclose(val, 0, abs_tol=1e-8)) * cut\n",
    "\n",
    "        if val >= 0:\n",
    "            for i in range(4):\n",
    "                yield 0\n",
    "\n",
    "    def chrom_sort(item):\n",
    "        \"\"\"\n",
    "        Sorts in a meaningful way for chromosomes.\n",
    "        \"\"\"\n",
    "        if item.startswith('chr'):\n",
    "            item = item[3:]\n",
    "        if item.isdigit():\n",
    "            return int(item)\n",
    "        else:\n",
    "            return item\n",
    "\n",
    "    def round_to_1_signif(x):\n",
    "        \"\"\"\n",
    "        Rounds to first significant digit.\n",
    "        \"\"\"\n",
    "        return round(x, -int(floor(log10(abs(x)))))\n",
    "\n",
    "    class SwapStyle(object):\n",
    "        def __init__(self, *args):\n",
    "            self.style = args\n",
    "        def __enter__(self):\n",
    "            self.orig = sns.axes_style()\n",
    "            sns.set_style(*self.style)\n",
    "        def __exit__(self ,type, value, traceback):\n",
    "            sns.set_style(self.orig)\n",
    "        \n",
    "    # set cut if not set\n",
    "    if cut is None:\n",
    "        cut = max(max(df[key]), max(-df[key])) / 3\n",
    "\n",
    "    # make the data frame to plot\n",
    "    row_iter = df.itertuples()\n",
    "    col_iterators = zip(*(horizon(row, key, cut) for row in row_iter))\n",
    "    col_names = ('yp1', 'yp2', 'yp3', 'yp4', \n",
    "                 'yn1', 'yn2', 'yn3', 'yn4')\n",
    "    df2 = (df.copy(deep=False)\n",
    "           .assign(**dict(zip(col_names, col_iterators)))\n",
    "          )\n",
    "\n",
    "    # chromosome names\n",
    "    chrom_names = list(df.groupby(chrom).groups.keys())\n",
    "    sorted_chrom_names = sorted(chrom_names, key=chrom_sort)\n",
    "    \n",
    "    if pop_sorting is None:\n",
    "        pop_sorting = sorted(set(df.reset_index()[pop]))\n",
    "    \n",
    "    # number of populations\n",
    "    nr_pop = len(df.groupby(pop).groups)\n",
    "    \n",
    "    # sizes of chromosomes\n",
    "    chrom_sizes = list()\n",
    "    for chrom_name in sorted_chrom_names:\n",
    "        chrom_subset = df.loc[df.chrom == chrom_name]\n",
    "        est_chrom_len = np.max(chrom_subset.start) + width\n",
    "        chrom_sizes.append(est_chrom_len)\n",
    "        \n",
    "    # relative width of each plot facet \n",
    "    # (using lengths of chromosomes)\n",
    "    facet_widths_ratios = chrom_sizes# * nr_pop\n",
    "\n",
    "    # make the plot\n",
    "    with SwapStyle('ticks'):\n",
    "\n",
    "        # make the facet grid\n",
    "        g = sns.FacetGrid(df2, \n",
    "                          col=chrom, \n",
    "                          row=pop,\n",
    "                          # sharex=False,\n",
    "                          sharex=True,\n",
    "                          # margin_titles=True,\n",
    "                          size=0.5, \n",
    "                          aspect=50,\n",
    "                          col_order=sorted_chrom_names,\n",
    "                          row_order=pop_sorting,                      \n",
    "                          gridspec_kws={'hspace':0.0, \n",
    "                                        \"width_ratios\": facet_widths_ratios}\n",
    "                         )\n",
    "\n",
    "        # plot colors\n",
    "        colours = sns.color_palette(\"Blues\", 3) + ['black'] + \\\n",
    "                  sns.color_palette(\"Reds\", 3) + ['grey']\n",
    "\n",
    "        # first y tick\n",
    "        ytic1 = round_to_1_signif(cut / 3)\n",
    "\n",
    "        for col_name, colour in zip(col_names, colours):\n",
    "            plt.setp(g.fig.texts, text=\"\") # hack to make y facet labels align...\n",
    "            # map barplots to each facet\n",
    "            g.map(plt.bar, \n",
    "                  start, \n",
    "                  col_name, \n",
    "                  edgecolor = \"none\", \n",
    "                  width=width, \n",
    "                  color=colour)\n",
    "            # no tick labels on x\n",
    "            g.set(xticklabels=[])\n",
    "            #g.set_titles('{col_name}', '{row_name}')\n",
    "    \n",
    "        g.set_ylabels('')\n",
    "\n",
    "        def add_pop_labels(pop_label, **kwargs):\n",
    "            p = pop_label.reset_index(drop=True)[0]\n",
    "            plt.annotate(p, xy=(1.005 , 0.5), xycoords='axes fraction', ha='left', size=8)\n",
    "\n",
    "        g.map(add_pop_labels, pop)\n",
    "\n",
    "        def add_chrom_labels(chrom_label, **kwargs):\n",
    "            p = chrom_label.reset_index(drop=True)[0]\n",
    "            plt.annotate(p, xy=(0.5 , 1.005), xycoords='axes fraction', ha='center', size=8)\n",
    "\n",
    "        g.map(add_chrom_labels, chrom)\n",
    "\n",
    "        for arr in g.axes:\n",
    "            for ax, max_val in zip(arr, facet_widths_ratios):\n",
    "                ax.set_xlim(0, max_val+1)\n",
    "                ax.set_ylim(0, cut)\n",
    "                ax.set(xlabel='', ylabel='')\n",
    "                ax.set(xticks=np.arange(0, max_val, round_to_1_signif(max_val) / 10))\n",
    "                ax.set(yticks=[ytic1, ytic1*2, ytic1*3])\n",
    "                g.set_titles('', '')\n",
    "              \n",
    "        # remove top and right frame\n",
    "        sns.despine()\n",
    "\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        plt.subplots_adjust(right=0.95)\n",
    "        \n",
    "        return g.fig\n",
    "\n",
    "\n",
    "n = 100\n",
    "df = pd.DataFrame({'chrom': ['chr11']*2*n + ['chr2']*2*n,\n",
    "                   'pop': ['EUR']*1*n + ['AFR']*1*n + ['EUR']*1*n + ['AFR']*1*n, \n",
    "                   'start': list(range(1*n)) * 4, \n",
    "                   'pi': list(np.sin(np.linspace(-np.pi, np.pi, 1*n))) * 4})\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "with Timer() as t:\n",
    "    with SwapContext(\"notebook\", font_scale=0.5):\n",
    "        fig = horizon_plot(df, 'pi', width=1, pop='pop')\n",
    "\n",
    "        # save to file\n",
    "        plt.savefig('tmp.pdf')\n",
    "#         fig.clf() # clean up memory\n",
    "        plt.close(fig)  # close to allow garbage collection, also suppresses inline plot\n",
    "#         gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'simons_pi_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5a70d643ed02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m df = simons_pi_data.assign(chrom = simons_pi_data.chr,\n\u001b[0m\u001b[1;32m    172\u001b[0m                            \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimons_pi_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                            end = simons_pi_data.pos*100000+100000)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'simons_pi_data' is not defined"
     ]
    }
   ],
   "source": [
    "df = simons_pi_data.assign(chrom = simons_pi_data.chr,\n",
    "                           start = simons_pi_data.pos*100000, \n",
    "                           end = simons_pi_data.pos*100000+100000)\n",
    "\n",
    "win_size = 1000000\n",
    "\n",
    "@window(size=win_size)\n",
    "def pi_mean(df):\n",
    "    return np.mean(df.pi_mean)\n",
    "\n",
    "with Timer() as t:\n",
    "    simons_pi_data_win = df.groupby(['chrom', 'popu']).apply(pi_mean)\n",
    "\n",
    "with Timer() as t:\n",
    "    with SwapContext(\"notebook\", font_scale=0.5):\n",
    "        fig = horizon_plot(simons_pi_data_win.reset_index(), \n",
    "                           'pi_mean', \n",
    "                           width=win_size, \n",
    "                           pop='popu',\n",
    "                           pop_sorting = pop_sorting,\n",
    "                           cut=0.0005) # width should be end-start\n",
    "        # save to file\n",
    "        plt.savefig('tmp.pdf')\n",
    "#         fig.clf() # clean up memory\n",
    "        plt.close(fig)  # close to allow garbage collection, also suppresses inline plot\n",
    "#         gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = simons_pi_data.assign(chrom = simons_pi_data.chr,\n",
    "                           start = simons_pi_data.pos*100000, \n",
    "                           end = simons_pi_data.pos*100000+100000)\n",
    "\n",
    "win_size = 100000\n",
    "\n",
    "@window(size=win_size)\n",
    "def pi_mean(df):\n",
    "    return np.mean(df.pi_mean)\n",
    "\n",
    "with Timer() as t:\n",
    "    simons_pi_data_win = df.groupby(['chrom', 'popu']).apply(pi_mean)\n",
    "\n",
    "with Timer() as t:\n",
    "    with SwapContext(\"notebook\", font_scale=0.5):\n",
    "        fig = horizon_plot(simons_pi_data_win.reset_index(), \n",
    "                           'pi_mean', \n",
    "                           width=win_size, \n",
    "                           pop='popu',\n",
    "                           pop_sorting = pop_sorting,\n",
    "                           cut=0.0005) # width should be end-start\n",
    "        # save to file\n",
    "        plt.savefig('tmp.pdf')\n",
    "        fig.clf() # clean up memory\n",
    "        plt.close(fig)  # close to allow garbage collection, also suppresses inline plot\n",
    "        gc.collect()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
